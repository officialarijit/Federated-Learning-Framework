{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential privacy: the Laplace mechanism\n",
    "\n",
    "We are now going to introduce the Laplace mechanism (see [The Algorithmic Foundations of Differential Privacy](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf), Section 3.3). \n",
    "Let $\\mathcal X$ be the set of possible rows in a database so that we can represent a particular database using a histogram $x\\in\\mathbb N^{|\\mathcal X|}$.\n",
    "\n",
    "Given a particular function $f:\\mathbb N^{|\\mathcal X|}\\rightarrow \\mathbb R^k$, we define the Laplace mechanism as the collection of conditional probabilities given by\n",
    "\n",
    "$$\n",
    "p(z|f(x); b) = \\prod_{i=1}^k \\frac{1}{2b} e^{-\\frac{1}{b}| f(x)_i - z_i| }\n",
    "$$\n",
    "\n",
    "where $z\\in\\mathbb R^k$. We can show that this mechanism is $\\epsilon$-differentially private with $\\epsilon = \\frac{\\Delta f}{b}$ and with the sensitivity $\\Delta f$ defined as\n",
    "\n",
    "$$\n",
    "\\Delta f = \\underset{||x-y||_1 = 1}{\\rm max} ||f(x) - f(y)||_1\\,.\n",
    "$$\n",
    "\n",
    "Notice that the Laplace mechanism is a randomization algorithm that depends on the function $f$, which can be regarded as a numeric query. In order to apply this mechanism for a particular value of $\\epsilon$, we need to compute $\\Delta f$, which might be hard to do, in practice. Furthermore, there are cases in which $\\Delta f$ is unbounded, so there is no way to make $\\epsilon$ finite. Thus, for practical purposes, we may find a compromise and, instead of using the worst-case-scenario $\\Delta f$, we can use a \"typical\" sensitivity. This typical sensitivity can be estimated by taking the databases $x, y$ to be random variables, which allows the distribution of $||f(x) - f(y)||_1$ to be computed.\n",
    "\n",
    "\n",
    "\n",
    "## Example: mean height\n",
    "\n",
    "We consider the case in which we want to estimate the mean height of a group of people. \n",
    "However, the people do not want to reveal their exact height, so some Laplace noise is introduced. \n",
    "The first thing we need to do is decide what amount of noise that should added to their true height.\n",
    "\n",
    "In this case, the database consists simply of one record, height, and the function $f$ returns the height. \n",
    "Now, since the height is not bounded, the sensitivity $\\Delta f$ is infinite. \n",
    "However, in practice, humans are typically not more than 2m tall and are never more than 3m tall. \n",
    "So this is a case in which the use of a typical sensitivity is in order.\n",
    "\n",
    "The amount of noise we should introduce depends on the typical value of the height of the general population. \n",
    "For example, adding noise of about 0.1cm is clearly too little. \n",
    "On the other hand, adding noise of about 1m is too much, in the sense that it would be useless to compute an average height.\n",
    "\n",
    "The distribution of heights of adult males is normal with mean $\\mu_M = 178\\,{\\rm cm}$ and $\\sigma_M = 7\\,{\\rm cm}$. Similarly, for females, the distribution is normal with $\\mu_F = 162\\,{\\rm cm}$ and $\\sigma_F = 6.5\\,{\\rm cm}$. Assuming that there are the same number of males and females, the height distribution would be\n",
    "\n",
    "$$\n",
    "p(h) = \\frac{1}{2}\\left [ \\mathcal N \\left (h\\,|\\,\\mu_M, \\sigma_M^2\\right ) + \\mathcal N\\left (h\\,|\\,\\mu_F, \\sigma_F^2\\right ) \\right ]\\,.\n",
    "$$\n",
    "\n",
    "The mean of the distribution of heights in the general population is $\\mu = \\frac{1}{2}(\\mu_M + \\mu_F)$ and the variance is given by\n",
    "\n",
    "$$\n",
    "\\sigma^2 = \\frac{1}{2}\\left ( \\sigma_M^2 + \\sigma_F^2 \\right ) + \\frac{1}{4}\\left ( \\mu_M - \\mu_F \\right )^2\\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "mu_M = 178\n",
    "mu_F = 162\n",
    "sigma_M = 7\n",
    "sigma_F = 6.5\n",
    "\n",
    "mu = 1/2 * (mu_M + mu_F)\n",
    "sigma = np.sqrt(1/2 * (sigma_M**2 + sigma_F**2) + 1/4 * (mu_M - mu_F)**2)\n",
    "\n",
    "x = np.arange(mu - sigma, mu + sigma, 0.001) # range of x in spec\n",
    "x_all = np.arange(0, 220, 0.001) # entire range of x, both in and out of spec\n",
    "y = 1/2 * (norm.pdf(x, mu_M, sigma_M) + norm.pdf(x, mu_F, sigma_F))\n",
    "y_M = norm.pdf(x_all, mu_M, sigma_M)\n",
    "y_F = norm.pdf(x_all, mu_F, sigma_F)\n",
    "y_T = 1/2 * (y_M + y_F)\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "ax.plot(x_all, y_M, label=\"Male\")\n",
    "ax.plot(x_all, y_F, label=\"Female\")\n",
    "ax.plot(x_all, y_T, label=\"General\")\n",
    "\n",
    "ax.fill_between(x, y, 0, alpha=0.3, color='y', label=\"$\\mu\\pm\\sigma$\")\n",
    "ax.fill_between(x_all, y_M, 0, alpha=0.1)\n",
    "ax.fill_between(x_all, y_F, 0, alpha=0.1)\n",
    "ax.fill_between(x_all, y_T, 0, alpha=0.1)\n",
    "ax.set_xlim([100, 220])\n",
    "ax.set_xlabel('height (cm)')\n",
    "ax.set_yticklabels([])\n",
    "ax.set_title('Height Distribution')\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to estimate the typical value of the sensitivity, we can compute its expected value $\\mathbb E[\\Delta f]$. This gives us\n",
    "\n",
    "$$\n",
    "\\mathbb E[\\Delta f] = \\frac{1}{2\\sqrt{\\pi}}\\left ( \\sigma_M + \\sigma_F + \\sqrt{2(\\sigma_M^2 + \\sigma_F^2)}\\left (e^{-m^2} + \\sqrt{\\pi}\\,m \\,{\\rm erf}(m)\\right ) \\right )\n",
    "$$\n",
    "\n",
    "with $m = \\frac{\\mu_M - \\mu_F}{\\sqrt{2(\\sigma_M^2 + \\sigma_F^2)}}$. In principle, we could use other statistics, such as $\\mathbb E[\\Delta f] + \\sigma$ or some high percentile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erf\n",
    "import math\n",
    "\n",
    "m = (mu_M - mu_F)/np.sqrt((2*(sigma_M**2 + sigma_F**2)))\n",
    "df = 1/(2*np.sqrt(math.pi)) * (sigma_M + sigma_F + np.sqrt(2*(sigma_M**2 + sigma_F**2)) \n",
    "                               * (np.exp(-m**2) + np.sqrt(math.pi)*m*erf(m) ) )\n",
    "\n",
    "print(\"Expected sensitivity: \" + str(round(df,2)) + \" cm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, in general, it is not possible to compute the expected value (or any other statistic) of $\\Delta f$ exactly. \n",
    "However, the statistics can be estimated using a sampling procedure (see [Rubinstein 2017](https://arxiv.org/pdf/1706.02562.pdf)). \n",
    "That is, instead of computing the global sensitivity $\\Delta f$ analytically, we compute an empirical estimation of it by sampling over the dataset.\n",
    "The framework provides a method for sampling the sensitivity (see the implementation [here](https://github.com/sherpaai/Sherpa.ai-Federated-Learning-Framework/blob/master/shfl/differential_privacy/sensitivity_sampler.py))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shfl.private import IdentityFunction\n",
    "from shfl.differential_privacy import GaussianMixture\n",
    "from shfl.differential_privacy import SensitivitySampler\n",
    "from shfl.differential_privacy import L1SensitivityNorm\n",
    "\n",
    "norm_params = np.array([[mu_M, sigma_M],\n",
    "                        [mu_F, sigma_F]])\n",
    "\n",
    "weights = np.ones(2) / 2.0\n",
    "distribution = GaussianMixture(norm_params, weights)\n",
    "\n",
    "sampler = SensitivitySampler()\n",
    "sensitivity, mean = sampler.sample_sensitivity(IdentityFunction(), L1SensitivityNorm(), distribution, n=1, gamma=0.05)\n",
    "print(\"Sensitivity from sampling: \" + str(round(sensitivity,2)))\n",
    "print(\"Mean sensitivity from sampling: \" + str(round(mean,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the value obtained is approximately the expected value for the sensitivity.\n",
    "\n",
    "For smaller values of $\\epsilon$ , the amount of privacy is higher, but the utility is lower. For example, if you wish to compute the mean height over a given population, the accuracy of the result would degrade as the amount of privacy increases. This is shown in the experiment below.\n",
    "\n",
    "In particular, we consider a population of 500 people with a mean height $true_mean$. \n",
    "However, these people reported their height with a Laplace noise controlled by $\\epsilon$ and the sensitivity $\\Delta f$, which is then used to estimate the mean height. \n",
    "As $\\epsilon$ decreases, the error in this estimate increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shfl.differential_privacy import LaplaceMechanism\n",
    "from shfl.private.federated_operation import federate_array\n",
    "\n",
    "def experiment(sensitivity, epsilon):\n",
    "    true_heights = np.random.normal(170, 1, 500)\n",
    "    true_mean = np.mean(true_heights)\n",
    "    \n",
    "    federated_array = federate_array(true_heights, len(true_heights))\n",
    "    \n",
    "    # Define allowed access to data. \n",
    "    data_access_definition = LaplaceMechanism(sensitivity, epsilon)\n",
    "    federated_array.configure_data_access(data_access_definition)\n",
    "    \n",
    "    # Query data\n",
    "    result = federated_array.query()\n",
    "    \n",
    "    observed_mean = np.mean(result)\n",
    "    error = np.abs(true_mean - observed_mean)\n",
    "    \n",
    "    return observed_mean, error\n",
    "\n",
    "def run_n_experiments(sensitivity, epsilon, n_runs):\n",
    "    for run in range(n_runs):\n",
    "        observed_mean, error = experiment(sensitivity, epsilon)\n",
    "        errors[i_df, i_epsilon] = errors[i_df, i_epsilon] + error\n",
    "        \n",
    "    return 1/n_runs * errors[i_df, i_epsilon]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the experiments:\n",
    "epsilon_range = np.arange(0.001, 3, 0.05)\n",
    "df_range = df + [0, sigma, 2*sigma]\n",
    "errors = np.zeros((len(df_range), len(epsilon_range)), dtype=object)\n",
    "\n",
    "n_runs = 1\n",
    "for i_df in range(len(df_range)):\n",
    "    for i_epsilon in range(len(epsilon_range)):\n",
    "        errors[i_df, i_epsilon] = run_n_experiments(df_range[i_df], epsilon_range[i_epsilon], n_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the figure:\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "labels = [\"$\\mathbb{E}[\\Delta f]$\", \"$\\mathbb{E}[\\Delta f] + \\sigma$\", \"$\\mathbb{E}[\\Delta f] + 2\\sigma$\"]\n",
    "for i_df in range(len(df_range)):\n",
    "    ax.plot(epsilon_range, errors[i_df], label = labels[i_df])\n",
    "ax.set_xlabel('$\\epsilon$')\n",
    "ax.set_ylabel('Error (cm)')\n",
    "ax.set_yscale('log')\n",
    "plt.legend(title = \"Sensitivity\", loc=\"upper right\")\n",
    "caption = \"The error grows as privacy increases (i.e. for smaller values of $\\epsilon$). \\n\\\n",
    "Moreover, for increasing values of the expected sensitivity $\\mathbb{E}[\\Delta f]$, \\n\\\n",
    "the privacy increases and thus the error grows.\"\n",
    "ax.text(0.1, 0.005, caption, ha='left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SherpaFL_py37",
   "language": "python",
   "name": "sherpafl_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
