{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential privacy: binary average attack\n",
    "\n",
    "\n",
    "The basic idea of differential privacy is to make a particular query stochastic so that the underlying data is kept private. The average attack consists of performing the same query many times, in order to reliably estimate the underlying data. This is, of course, not desirable; so we should either limit the number of queries or design algorithms that are not vulnerable to this kind of attack.\n",
    "\n",
    "In this notebook, we present a simple example of this phenomenon, based on a single node that contains one binary number $n$ that encodes whether the node is guilty ($n=1$) or innocent ($n=0$). \n",
    "A randomized response algorithm (see [The Algorithmic Foundations of Differential Privacy](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf), Section 3.2, and the notebook [Basic concepts](./differential_privacy_basic_concepts.ipynb)) is used to query the node, in order to preserve the privacy of $n$.\n",
    "Moreover, the use of Adaptive Differential Privacy for privacy protection is illustrated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average attack simulation\n",
    "\n",
    "We start by creating a single node that contains a binary number. In this case, we set this number to 1 (guilty). By setting f1=0.8, we make sure that 80% of the times we query the node whose data is 1, we get an answer of 1. In the remaining 20% of the cases we obtain an answer of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from shfl.private.node import DataNode\n",
    "from shfl.differential_privacy.dp_mechanism import RandomizedResponseBinary\n",
    "from math import log, exp\n",
    "\n",
    "n = 1 #the node is guilty\n",
    "\n",
    "node_single = DataNode()\n",
    "node_single.set_private_data(name=\"guilty\", data=np.array([n]))\n",
    "data_access_definition = RandomizedResponseBinary(f0=0.8, f1=0.8, epsilon=log(4) + 1e-10)\n",
    "node_single.configure_data_access(\"guilty\", data_access_definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we perform the query just once, we cannot be sure that the result matches the true data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = node_single.query(private_property=\"guilty\")\n",
    "print(\"The result of one query is: \" + str(int(result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we perform the query $N$ times and take the average, we can estimate the true data with an error that goes towards zero as $N$ increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "result_query = []\n",
    "for i in range(N):\n",
    "    result_query.append(node_single.query(private_property=\"guilty\"))\n",
    "result_query = np.array(result_query)\n",
    "print(np.mean(result_query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the average result of the query is close to 0.8. This allows us to conclude that the raw answer is most likely 1. Otherwise, the result would have been close to 0.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permanent randomized response\n",
    "\n",
    "A possible solution to this problem (e.g. see [RAPPOR technology](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/42852.pdf) and [Jiang 2019](https://www.sciencedirect.com/science/article/pii/S0020025518310429)) is to create a node that contains two pieces of information: the true data and a **permanent randomized response** (PRR). The latter is initialized to None and, once the node receives the first query, it creates a random binary number following the algorithm described above, which is saved as the PRR. The result of the query is then a randomized response using the PRR as input. This way, even if the query is performed a large number of times, the attacker can only guess the PRR with certainty, not the true data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_single_prr = DataNode()\n",
    "data_binary = np.array([1])  #the node is guilty\n",
    "node_single_prr.set_private_data(name=\"guilty\", data=np.array([n]))\n",
    "node_single_prr.configure_data_access(\"guilty\", data_access_definition)\n",
    "\n",
    "permanent_response = node_single_prr.query(private_property=\"guilty\")\n",
    "print(\"The PRR is: \" + str(int(permanent_response)))\n",
    "\n",
    "# we save the prr as a new piece of information\n",
    "node_single_prr.set_private_data(name=\"guilty\", data=np.append(data_binary, permanent_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, all the external queries are done over the permanent randomized data, while the raw data remains completely hidden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "result_query = np.empty(shape=(N,))\n",
    "for i in range(N):\n",
    "    result_query[i] = node_single_prr.query(private_property=\"guilty\")[1]\n",
    "print(np.mean(result_query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is not always close to 0.8, since the permanent response might be 0. The average attack may, at best, identify the permanent randomized response, but not the raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive differential privacy\n",
    "\n",
    "Adaptive Differential Privacy is a different approach to managing multiple queries against the same data. The basic idea consists of registering all the interactions until a global epsilon is spent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shfl.differential_privacy.composition_dp import AdaptiveDifferentialPrivacy\n",
    "from shfl.differential_privacy.composition_dp import ExceededPrivacyBudgetError\n",
    "\n",
    "global_epsilon_delta = (7, 0)\n",
    "\n",
    "node_single = DataNode()\n",
    "node_single.set_private_data(name=\"guilty\", data=np.array([n]))\n",
    "\n",
    "data_access_definition = AdaptiveDifferentialPrivacy(global_epsilon_delta)\n",
    "\n",
    "differentially_private_mechanism = RandomizedResponseBinary(f0=0.8, f1=0.8, epsilon=log(4) + 1e-10)\n",
    "node_single.configure_data_access(\"guilty\", data_access_definition)\n",
    "\n",
    "N = 500\n",
    "result_query = []\n",
    "for i in range(N):\n",
    "    try:\n",
    "        result_query.append(node_single.query(private_property=\"guilty\", \n",
    "                                              differentially_private_mechanism=differentially_private_mechanism))\n",
    "    except ExceededPrivacyBudgetError:\n",
    "        print(\"The privacy budget has been spent at run {}\".format(i+1))\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SherpaFL_py37",
   "language": "python",
   "name": "sherpafl_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
