{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated models: regression using the California housing database\n",
    "\n",
    "In this notebook, we explain how you can use a federated learning environment to create a regression model. \n",
    "In the notebook on [Linear regression for a simple 2D case](./federated_models_linear_regression.ipynb), we explained the basic concepts of the framework, so now we will go slightly faster.\n",
    "## The data \n",
    "First, we load a dataset (included in the framework) to allow for regression experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shfl\n",
    "from shfl.data_base.california_housing import CaliforniaHousing\n",
    "\n",
    "database = CaliforniaHousing()\n",
    "train_data, train_labels, test_data, test_labels = database.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to explore the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of train_data: \" + str(train_data.shape))\n",
    "print(\"Shape of train_labels: \" + str(train_labels.shape))\n",
    "print(\"One sample features: \" + str(train_data[0]))\n",
    "print(\"One sample label: \" + str(train_labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "Model definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def model_builder():\n",
    "    # create model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(8, input_dim=8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    # Define configuration\n",
    "    criterion = tf.keras.losses.MeanSquaredError()\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    metrics = [tf.keras.metrics.mae]\n",
    "    \n",
    "    return shfl.model.DeepLearningModel(model=model, criterion=criterion, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the federated learning experiment\n",
    "Federated environment definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid_distribution = shfl.data_distribution.IidDataDistribution(database)\n",
    "federated_data, test_data, test_label = iid_distribution.get_federated_data(num_nodes=20, percent=10)\n",
    "\n",
    "aggregator = shfl.federated_aggregator.FedAvgAggregator()\n",
    "federated_government = shfl.federated_government.FederatedGovernment(model_builder, federated_data, aggregator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Reshape(shfl.private.FederatedTransformation):\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.label = np.reshape(labeled_data.label, (labeled_data.label.shape[0], 1))\n",
    "        \n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Reshape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = np.reshape(test_label, (test_label.shape[0], 1))\n",
    "federated_government.run_rounds(3, test_data, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add differential privacy \n",
    "\n",
    "We wish to add Differential Privacy to our federated learning experiment, and assess its effect on the quality of the global model. In the following, it is shown how to perform that by easy steps using Sherpa.ai framework. As shown below, by selecting a sensitivity we are ready to run the private federated experiment using the desired differential privacy mechanism.\n",
    "\n",
    "### Model's sensitivity\n",
    "We will apply the Laplace mechanism, employing a fixed sensitivity for the model. \n",
    "Intuitively, the model's sensitivity is defined as the maximum change in the output when one single training data is changed or removed.\n",
    "The choice of the sensitivity is critical since it determines the amount of noise applied to the data, and thus excessive distortion might result in an unusable model.\n",
    "We can sample model's sensitivity using the functionality provided by the framework: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shfl.differential_privacy import SensitivitySampler\n",
    "from shfl.differential_privacy import L1SensitivityNorm\n",
    "\n",
    "\n",
    "class UniformDistribution(shfl.differential_privacy.ProbabilityDistribution):\n",
    "    \"\"\"\n",
    "    Implement Uniform sampling over the data\n",
    "    \"\"\"\n",
    "    def __init__(self, sample_data):\n",
    "        self._sample_data = sample_data\n",
    "\n",
    "    def sample(self, sample_size):\n",
    "        row_indices = np.random.randint(low=0, high=self._sample_data.shape[0], size=sample_size, dtype='l')\n",
    "        \n",
    "        return self._sample_data[row_indices, :]\n",
    "    \n",
    "\n",
    "class DeepLearningSample(shfl.model.DeepLearningModel):\n",
    "    \"\"\"\n",
    "    Adds the \"get\" method to model's class\n",
    "    \"\"\"\n",
    "    def get(self, data_array):\n",
    "        data = data_array[:, 0:-1]\n",
    "        labels = data_array[:, -1].reshape(-1,1)\n",
    "        train_model = self.train(data, labels)\n",
    "        \n",
    "        return self.get_model_params()\n",
    "\n",
    "\n",
    "def model_builder_sample():\n",
    "    # create model\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(8, input_dim=8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    # Define configuration\n",
    "    criterion = tf.keras.losses.MeanSquaredError()\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    metrics = [tf.keras.metrics.mae]\n",
    "    \n",
    "    return DeepLearningSample(model=model, criterion=criterion, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "\n",
    "class L1SensitivityNormLists(L1SensitivityNorm):\n",
    "    \"\"\"\n",
    "    Implements the L1 norm of the difference between lists of parameters x_1 and x_2\n",
    "    \"\"\"\n",
    "    def compute(self, x_1, x_2):\n",
    "        x = []\n",
    "        for x_1_i, x_2_i in zip(x_1, x_2):\n",
    "            x.append(np.sum(np.abs(x_1_i - x_2_i)))   \n",
    "        \n",
    "        return np.max(x) # This could be allowed to be an array\n",
    "\n",
    "    \n",
    "sample_data = np.hstack((train_data, train_labels.reshape(-1,1)))\n",
    "distribution = UniformDistribution(sample_data)\n",
    "sampler = SensitivitySampler()\n",
    "n_samples = 100\n",
    "max_sensitivity, mean_sensitivity = sampler.sample_sensitivity(\n",
    "    model_builder_sample(), \n",
    "    L1SensitivityNormLists(), distribution, n=n_samples, gamma=0.05)\n",
    "print(\"Max sensitivity from sampling: \" + str(max_sensitivity))\n",
    "print(\"Mean sensitivity from sampling: \" + str(mean_sensitivity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the federated learning experiment with differential privacy\n",
    "The Laplace mechanism provided by the Sherpa.ai Federated Learning and Differential Privacy Framework is then assigned as the private access type to the model parameters of each client in a new `FederatedGovernment` object. \n",
    "This results in an $\\epsilon$-differentially private FL model.\n",
    "For example, by choosing the value $\\epsilon = 0.5$, we can run the FL experiment with DP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shfl.differential_privacy import LaplaceMechanism\n",
    "\n",
    "params_access_definition = LaplaceMechanism(sensitivity=mean_sensitivity, epsilon=0.5)\n",
    "federated_governmentDP = shfl.federated_government.FederatedGovernment(\n",
    "    model_builder, federated_data, aggregator, model_params_access=params_access_definition)\n",
    "federated_governmentDP.run_rounds(3, test_data, test_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
