{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated models: linear regression\n",
    "Here, we explain how to set up a Linear Regression experiment in the Federated setting using the Sherpa.ai Federated Learning and Differential Privacy Framework. \n",
    "Results from federated learning are compared to (non-federated) centralized learning. \n",
    "Moreover, we also show how the addition of differential privacy affects the performance of the federated model. \n",
    "Ultimately, an application of the composition theorems for adaptive differential privacy is given. \n",
    "\n",
    "## The data\n",
    "In the present example, we will use the [California Housing dataset from sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html). \n",
    "We only make use of two features, in order to reduce the variance in the prediction. \n",
    "The Sherpa.ai Federated Learning and Differential Privacy Framework allows a generic dataset to easily be converted, to interact with the platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [],
   "source": [
    "import shfl\n",
    "from shfl.data_base.data_base import LabeledDatabase\n",
    "import sklearn.datasets\n",
    "import numpy as np\n",
    "from shfl.private.reproducibility import Reproducibility\n",
    "\n",
    "# Comment to turn off reproducibility:\n",
    "Reproducibility(1234)\n",
    "\n",
    "all_data = sklearn.datasets.fetch_california_housing()\n",
    "n_features = 2\n",
    "data = all_data[\"data\"][:,0:n_features]\n",
    "labels = all_data[\"target\"]    \n",
    "\n",
    "# Retain part for DP sensitivity sampling:\n",
    "size = 2000\n",
    "sampling_data = data[-size:, ]\n",
    "sampling_labels = labels[-size:, ]\n",
    "\n",
    "# Create database:\n",
    "database = LabeledDatabase(data[0:-size, ], labels[0:-size])\n",
    "train_data, train_labels, test_data, test_labels = database.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Shape of training and test data: \" + str(train_data.shape) + str(test_data.shape))\n",
    "print(\"Total: \" + str(train_data.shape[0] + test_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will simulate a FL scenario by distributing the training data over a collection of clients, assuming an IID setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iid_distribution = shfl.data_distribution.IidDataDistribution(database)\n",
    "federated_data, test_data, test_labels = iid_distribution.get_federated_data(num_nodes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model\n",
    "At this stage, we need to define the linear regression model. The linear regression model is encapsulated in the Sherpa.ai framework and thus readily usable. We choose the federated aggregator to be the average of the client models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shfl.model.linear_regression_model import LinearRegressionModel\n",
    "\n",
    "def model_builder():\n",
    "    model = LinearRegressionModel(n_features=n_features, n_targets=1)\n",
    "    return model\n",
    "\n",
    "aggregator = shfl.federated_aggregator.FedAvgAggregator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the federated learning experiment\n",
    "We're now ready to run the FL model. \n",
    "The Sherpa.ai Federated Learning and Differential Privacy Framework offers support for the Linear Regression model from [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). \n",
    "The user must specify the number of features and targets, in advance.\n",
    "Note that in this case, we set the number of rounds `n=1` since no iterations are needed in the case of linear regression. \n",
    "The performance metrics used are the Root Mean Squared Error (RMSE) and the $R^2$ score.\n",
    "It can be observed that the performance of the global model (i.e., the aggregated model) is generally superior with respect to the performance of each node, thus, the federated learning approach proves to be beneficial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_government = shfl.federated_government.FederatedGovernment(model_builder, federated_data, aggregator)\n",
    "federated_government.run_rounds(n=1, test_data=test_data, test_label=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can observe that the performance is comparable to the centralized learning model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Comparison with centralized model:\n",
    "centralized_model = LinearRegressionModel(n_features=n_features, n_targets=1)\n",
    "centralized_model.train(data=train_data, labels=train_labels)\n",
    "print(centralized_model.evaluate(data=test_data, labels=test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add differential privacy\n",
    "We want to assess the impact of differential privacy (see [The Algorithmic Foundations of Differential Privacy](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf), Section 3.3) on the federated model's performance.\n",
    "### Model's sensitivity\n",
    "In the case of applying the Laplace privacy mechanism (see [Laplace mechanism notebook](../differential_privacy/differential_privacy_laplace.ipynb)), the noise added has to be of the same order as the sensitivity of the model's output, i.e., the model parameters of our linear regression. \n",
    "In the general case, the model's sensitivity might be difficult to compute analytically. \n",
    "An alternative approach is to attain random differential privacy through a sampling over the data (e.g., see [Rubinstein 2017](https://arxiv.org/abs/1706.02562). \n",
    "That is, instead of computing the global sensitivity $\\Delta f$ analytically, we compute an empirical estimation of it by sampling over the dataset.\n",
    "However, be advised that this will guarantee the weaker property of random differential privacy.\n",
    "This approach is convenient, since it allows for the sensitivity estimation of an arbitrary model or a black-box computer function.\n",
    "The Sherpa.ai Federated Learning and Differential Privacy Framework provides this functionality in the class `SensitivitySampler`.\n",
    "\n",
    "We need to specify a distribution of the data to sample from. \n",
    "Generally, this requires previous knowledge and/or model assumptions. \n",
    "In order not to make any specific assumptions about the distribution of the dataset, we can choose a uniform distribution. \n",
    "We define our class of `ProbabilityDistribution` that uniformly samples over a data-frame.\n",
    "We use the previously retained part of the dataset for sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformDistribution(shfl.differential_privacy.ProbabilityDistribution):\n",
    "    \"\"\"\n",
    "    Implement Uniform sampling over the data\n",
    "    \"\"\"\n",
    "    def __init__(self, sample_data):\n",
    "        self._sample_data = sample_data\n",
    "\n",
    "    def sample(self, sample_size):\n",
    "        row_indices = np.random.randint(low=0, high=self._sample_data.shape[0], size=sample_size, dtype='l')\n",
    "        \n",
    "        return self._sample_data[row_indices, :]\n",
    "    \n",
    "sample_data = np.hstack((sampling_data, sampling_labels.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `SensitivitySampler` implements the sampling, given a query, i.e., the learning model itself, in this case.\n",
    "We only need to add the `get` method to our model since it is required by the class `SensitivitySampler`. \n",
    "We choose the sensitivity norm to be the $L_1$ norm and we apply the sampling. \n",
    "The value of the sensitivity depends on the number of samples `n`: the more samples we perform, the more accurate the sensitivity. \n",
    "Indeed, upon increasing the number of samples `n`, the sensitivity becomes more accurate and typically decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shfl.differential_privacy import SensitivitySampler\n",
    "from shfl.differential_privacy import L1SensitivityNorm\n",
    "\n",
    "class LinearRegressionSample(LinearRegressionModel):\n",
    "    \n",
    "    def get(self, data_array):\n",
    "        data = data_array[:, 0:-1]\n",
    "        labels = data_array[:, -1]\n",
    "        train_model = self.train(data, labels)\n",
    "      \n",
    "        return self.get_model_params()\n",
    "\n",
    "distribution = UniformDistribution(sample_data)\n",
    "sampler = SensitivitySampler()\n",
    "n_samples = 4000\n",
    "max_sensitivity, mean_sensitivity = sampler.sample_sensitivity(\n",
    "    LinearRegressionSample(n_features=n_features, n_targets=1), \n",
    "    L1SensitivityNorm(), distribution, n=n_samples, gamma=0.05)\n",
    "print(\"Max sensitivity from sampling: \" + str(max_sensitivity))\n",
    "print(\"Mean sensitivity from sampling: \" + str(mean_sensitivity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, sampling over a dataset involves the training of the model on two datasets differing in one entry, at each sample.\n",
    "Thus, in general, this procedure might be computationally expensive (e.g. in the case of training a deep neural network)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the federated learning experiment with differential privacy\n",
    "At this stage, we are ready to add a layer of DP to our federated learning model. \n",
    "We will apply the Laplace mechanism, employing the sensitivity obtained from the previous sampling. \n",
    "The Laplace mechanism provided by the Sherpa.ai Federated Learning and Differential Privacy Framework is then assigned as the private access type to the model parameters of each client in a new `FederatedGovernment` object. \n",
    "This results in an $\\epsilon$-differentially private FL model.\n",
    "For example, by choosing the value $\\epsilon = 0.5$, we can run the FL experiment with DP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shfl.differential_privacy import LaplaceMechanism\n",
    "\n",
    "params_access_definition = LaplaceMechanism(sensitivity=max_sensitivity, epsilon=0.5)\n",
    "federated_governmentDP = shfl.federated_government.FederatedGovernment(\n",
    "    model_builder, federated_data, aggregator, model_params_access=params_access_definition)\n",
    "federated_governmentDP.run_rounds(n=1, test_data=test_data, test_label=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example we saw that the performance of the model deteriorated slightly, due to the addition of differential privacy. \n",
    "It must be noted that each run involves a different random noise added by the differential privacy mechanism.\n",
    "However, in general, privacy increases at the expense of accuracy (i.e. for smaller values of $\\epsilon$).\n",
    "This can be observed by calculating a mean of several runs, as explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple queries: composition of differential private mechanisms using adaptivity\n",
    "Now, we will explain the application of the composition theorems using adaptivity, as implemented in Sherpa.ai Federated Learning and Differential Privacy Framework (see the [Composition concepts notebook](../differential_privacy/differential_privacy_composition_concepts.ipynb)).\n",
    "The idea is to stop when the privacy budget is expended.\n",
    "This happens when the same query is executed on the client dataset, as this might disclose sensitive information (see [The Algorithmic Foundations of Differential Privacy](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf), Section 3.5.2).\n",
    "Note that, when applying the composition theorems for privacy filters in the present example, we are assuming that the estimated sensitivity is a good enough approximation of the analytic sensitivity (see [Rogers 2016](https://papers.nips.cc/paper/6170-privacy-odometers-and-filters-pay-as-you-go-composition.pdf)).\n",
    "\n",
    "In the following experiment, we set a privacy budget (variable `global_epsilon_delta = (4, 0)`), and we consider different values of $\\epsilon$ for the query (variable `epsilon_range = np.array([0.2,0.5,0.8])`). \n",
    "In each case, the execution automatically exits when the privacy budget is expended. \n",
    "Taking the average of the performance metrics, we can verify that the accuracy increases for larger values of $\\epsilon$, which is associated with lower privacy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Run several runs with different levels of privacy: for fixed sensitivity, we use different values of epsilon\n",
    "from shfl.differential_privacy.composition_dp import AdaptiveDifferentialPrivacy\n",
    "from shfl.differential_privacy.composition_dp import ExceededPrivacyBudgetError\n",
    "\n",
    "global_epsilon_delta = (4, 0) \n",
    "epsilon_range = np.array([0.2,0.5,0.8])\n",
    "gl_evaluationDP = np.zeros((epsilon_range.size, 2))\n",
    "\n",
    "for i_epsilon in range(epsilon_range.size):\n",
    "    print(\"---------------------------\\n\")\n",
    "    print(\"epsilon = \" + str(epsilon_range[i_epsilon]))\n",
    "    \n",
    "    dpm = LaplaceMechanism(sensitivity=max_sensitivity, epsilon=epsilon_range[i_epsilon])\n",
    "    \n",
    "    params_access_definition = AdaptiveDifferentialPrivacy(global_epsilon_delta, differentially_private_mechanism=dpm)\n",
    "    federated_governmentDP = shfl.federated_government.FederatedGovernment(\n",
    "        model_builder, federated_data, aggregator, model_params_access=params_access_definition)\n",
    "    i_run = 0\n",
    "    while True:\n",
    "        try:\n",
    "            # Queries are performed using the Laplace mechanism\n",
    "            #print(\"i_run = \" + str(i_run))\n",
    "            federated_governmentDP.run_rounds(n=1, test_data=test_data, test_label=test_labels)\n",
    "            print(\"Executed i_run = \" + str(i_run))\n",
    "            gl_evaluationDP[i_epsilon,:] += np.asarray(federated_governmentDP._model.evaluate(data=test_data, labels=test_labels))\n",
    "            print(\"\\n\")\n",
    "            i_run += 1\n",
    "        except ExceededPrivacyBudgetError:\n",
    "            # At this point we have spent all our privacy budget\n",
    "            print(\"Reached privacy budget at i_run = \" + str(i_run))\n",
    "            print(\"\\n\")\n",
    "            gl_evaluationDP[i_epsilon,:] = np.divide(gl_evaluationDP[i_epsilon,:], i_run)\n",
    "            break \n",
    "        \n",
    "print(\"Mean performance: \\n\" + str(gl_evaluationDP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SherpaFL_py37",
   "language": "python",
   "name": "sherpafl_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
