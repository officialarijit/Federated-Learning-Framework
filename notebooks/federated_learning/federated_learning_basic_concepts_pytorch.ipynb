{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning: using a PyTorch model\n",
    "\n",
    "This notebook is a copy of the notebook [Federated learning basic concepts](./federated_learning_basic_concepts.ipynb). The difference is that, here, the model is built using PyTorch. However, apart from that, the structure is identical so the text has been removed for clearness. Please refer to the original notebook for the detailed description of the experiment. \n",
    "\n",
    "## The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shfl\n",
    "\n",
    "database = shfl.data_base.Emnist()\n",
    "train_data, train_labels, test_data, test_labels = database.load_data()\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(type(train_data[0]))\n",
    "train_data[0].shape\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(train_data[0])\n",
    "\n",
    "iid_distribution = shfl.data_distribution.IidDataDistribution(database)\n",
    "federated_data, test_data, test_label = iid_distribution.get_federated_data(num_nodes=20, percent=10)\n",
    "\n",
    "print(type(federated_data))\n",
    "print(federated_data.num_nodes())\n",
    "federated_data[0].private_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    # Arguments:\n",
    "        y_pred: Predictions with shape BxC (B: batch lenght; C: number of classes). Sum 1 for row.\n",
    "        y_true: Labels for data with One Hot Encoded format\n",
    "    \"\"\"\n",
    "    return accuracy_score(np.argmax(y_pred, -1), np.argmax(y_true, -1))\n",
    "\n",
    "def f1(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    # Arguments:\n",
    "        y_pred: Predictions with shape BxC (B: batch lenght; C: number of classes). Sum 1 for row.\n",
    "        y_true: Labels for data with One Hot Encoded format\n",
    "    \"\"\"\n",
    "    return f1_score(np.argmax(y_pred, -1), np.argmax(y_true, -1), average='macro')\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "    \n",
    "\n",
    "def model_builder():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(1, 32, kernel_size=(3, 3), stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Dropout(.4),\n",
    "        nn.Conv2d(32, 32, kernel_size=(3, 3), stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Dropout(.3),\n",
    "        Flatten(),\n",
    "        nn.Linear(1568, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(.1),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 10),\n",
    "        nn.Softmax(dim=1)\n",
    "\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=0.001, eps=1e-07)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    return shfl.model.DeepLearningModelPyTorch(model=model, criterion=criterion, optimizer=optimizer,\n",
    "                                               device=device, metrics={'accuracy':accuracy, 'f1':f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator = shfl.federated_aggregator.FedAvgAggregator()\n",
    "federated_government = shfl.federated_government.FederatedGovernment(model_builder, federated_data, aggregator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Reshape(shfl.private.FederatedTransformation):\n",
    "\n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = np.reshape(labeled_data.data, (\n",
    "        labeled_data.data.shape[0], 1, labeled_data.data.shape[1], labeled_data.data.shape[2]))\n",
    "\n",
    "class Normalize(shfl.private.FederatedTransformation):\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.__mean = mean\n",
    "        self.__std = std\n",
    "\n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = (labeled_data.data - self.__mean) / self.__std\n",
    "        \n",
    "        \n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Reshape())\n",
    "mean = np.mean(train_data.data)\n",
    "std = np.std(train_data.data)\n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Normalize(mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.reshape(test_data, (test_data.shape[0], 1, test_data.shape[1], test_data.shape[2]))\n",
    "test_data = (test_data - mean) / std\n",
    "federated_government.run_rounds(3, test_data, test_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
