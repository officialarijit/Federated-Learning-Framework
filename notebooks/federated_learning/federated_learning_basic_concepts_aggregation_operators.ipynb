{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning: aggregation operators\n",
    "\n",
    "In this notebook, we provide an explanation of the implementation of the different federated aggregation operators provided in the framework. Before discussing the different aggregation operators, we must establish the federated configuration (for more information see notebook [Federated learning basic concepts](./federated_learning_basic_concepts.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import shfl\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "database = shfl.data_base.Emnist()\n",
    "train_data, train_labels, test_data, test_labels = database.load_data()\n",
    "\n",
    "iid_distribution = shfl.data_distribution.IidDataDistribution(database)\n",
    "federated_data, test_data, test_labels = iid_distribution.get_federated_data(num_nodes=5, percent=10)\n",
    "\n",
    "def model_builder():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', strides=1, input_shape=(28, 28, 1)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(tf.keras.layers.Dropout(0.4))\n",
    "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', strides=1))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    criterion = tf.keras.losses.CategoricalCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.RMSprop()\n",
    "    metrics = [tf.keras.metrics.categorical_accuracy]\n",
    "    \n",
    "    return shfl.model.DeepLearningModel(model=model, criterion=criterion, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "\n",
    "class Reshape(shfl.private.FederatedTransformation):\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = np.reshape(labeled_data.data, (labeled_data.data.shape[0], labeled_data.data.shape[1], labeled_data.data.shape[2],1))\n",
    "        \n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Reshape())\n",
    "\n",
    "class Normalize(shfl.private.FederatedTransformation):\n",
    "    \n",
    "    def __init__(self, mean, std):\n",
    "        self.__mean = mean\n",
    "        self.__std = std\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = (labeled_data.data - self.__mean)/self.__std\n",
    "        \n",
    "        \n",
    "mean = np.mean(train_data.data)\n",
    "std = np.std(train_data.data)\n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Normalize(mean, std))\n",
    "\n",
    "test_data = np.reshape(test_data, (test_data.shape[0], test_data.shape[1], test_data.shape[2],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have loaded and federated the data and established the learning model, the only step that remains is to establish the aggregation operator. At the moment, the framework has FedAvg and WeightedFedAvg implemented. The implementation of the federated aggregation operators are as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated averaging operator\n",
    "\n",
    "In this section, we detail the implementation of `FedAvg` (see [FedAvg](https://github.com/sherpaai/Sherpa.ai-Federated-Learning-Framework/blob/master/shfl/federated_aggregator/fedavg_aggregator.py)) proposed  by Google in this [paper](https://arxiv.org/abs/1602.05629). \n",
    "\n",
    "It is based on the arithmetic mean of the local weights $W_i$ trained in each of the local clients $C_i$. That is, the weights $W$ of the global model after each round of training are\n",
    "\n",
    "$$W = \\frac{1}{n_{\\rm{C}}} \\sum_{i=1}^{n_{\\rm{C}}} W_i$$\n",
    "\n",
    "\n",
    "For its implementation, we create a class that implements the [FederatedAggregator](https://github.com/sherpaai/Sherpa.ai-Federated-Learning-Framework/blob/master/shfl/federated_aggregator/federated_aggregator.py) interface. The method aggregate_weights is overwritten by calculating the mean of the local weights of each client. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from shfl.federated_aggregator.federated_aggregator import FederatedAggregator\n",
    "\n",
    "\n",
    "class FedAvgAggregator(FederatedAggregator):\n",
    "    \"\"\"\n",
    "    Implementation of Federated Averaging Aggregator. It only uses a simple average of the parameters of all the models\n",
    "    \"\"\"\n",
    "\n",
    "    def aggregate_weights(self, clients_params):\n",
    "        clients_params_array = np.array(clients_params)\n",
    "\n",
    "        num_clients = clients_params_array.shape[0]\n",
    "        num_layers = clients_params_array.shape[1]\n",
    "\n",
    "        aggregated_weights = np.array([np.mean(clients_params_array[:, layer], axis=0) for layer in range(num_layers)])\n",
    "\n",
    "        return aggregated_weights\n",
    "\n",
    "\n",
    "fedavg_aggregator = FedAvgAggregator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted federated averaging operator\n",
    "\n",
    "In this section, we detail the implementation of `WeightedFedAvg` (see [WeightedFedAvg](https://github.com/sherpaai/Sherpa.ai-Federated-Learning-Framework/blob/master/shfl/federated_aggregator/weighted_fedavg_aggregator.py)). It is the weighted version of `FedAvg`. The weight of each client $C_i$ is determined by the amount of client data $n_i$ with respect to total training data $n$. That is, the parameters $W$ of the global model after each round of training are:\n",
    "\n",
    "$$W =  \\sum_{i=1}^n \\frac{n_i}{n} W_i$$\n",
    "\n",
    "When all clients have the same amount of data, it is equivalent to FedAvg.\n",
    "\n",
    "To implement it, we create a class that implements the `FederatedAggregator` interface. The method `aggregate_weights` is overwritten by calculating the weighted mean of the local parameters of each client. For this purpose, we first weigh the local parameters by percentage and then sum the weighted parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from shfl.federated_aggregator.federated_aggregator import FederatedAggregator\n",
    "\n",
    "\n",
    "class WeightedFedAvgAggregator(FederatedAggregator):\n",
    "    \"\"\"\n",
    "    Implementation of Weighted Federated Averaging Aggregator. The aggregation of the parameters is based in the number of data \\\n",
    "    in every node.\n",
    "    \"\"\"\n",
    "\n",
    "    def aggregate_weights(self, clients_params):\n",
    "        clients_params_array = np.array(clients_params)\n",
    "\n",
    "        num_clients = clients_params_array.shape[0]\n",
    "        num_layers = clients_params_array.shape[1]\n",
    "\n",
    "        ponderated_weights = np.array([self._percentage[client] * clients_params_array[client, :] for client in range(num_clients)])\n",
    "        aggregated_weights = np.array([np.sum(ponderated_weights[:, layer], axis=0) for layer in range(num_layers)])\n",
    "\n",
    "        return aggregated_weights\n",
    "    \n",
    "weighted_fedavg_aggregator = WeightedFedAvgAggregator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are ready to establish the federated government with any of the implemented aggregation operators and start the federated learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_government = shfl.federated_government.FederatedGovernment(model_builder, federated_data, fedavg_aggregator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_government.run_rounds(1, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster federated averaging operator\n",
    "\n",
    "In this section, we detail the implementation of `ClusterFedAvg` (see [ClusterFedAvg](https://github.com/sherpaai/Sherpa.ai-Federated-Learning-Framework/blob/master/shfl/federated_aggregator/cluster_fedavg_aggregator.py)). \n",
    "\n",
    "Cluster Federated Averaging is based on the aggregation operator used for k-means clustering. When aggregating the centroids of a federated K-means clustering, we are faced with the problem of grouping the clusters for subsequent aggregation. Based on the hypothesis that the closest centroids will belong to the same cluster, we apply K-means over the centroids, in order to group the centroids that belong to the same cluster and to obtain the representation (aggregation) of each group. We choose the new centroids obtained as the aggregation.\n",
    "\n",
    "To implement it, we create a class that implements the `FederatedAggregator` interface. The method `aggregate_weights` is overwritten by applying K-means to the clients centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shfl.federated_aggregator.federated_aggregator import FederatedAggregator\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "class ClusterFedAvgAggregator(FederatedAggregator):\n",
    "    \"\"\"\n",
    "    Implementation of Cluster Average Federated Aggregator.\n",
    "    It adds another k-means to find the minimum distance of cluster centroids coming from each node.\n",
    "    \"\"\"\n",
    "\n",
    "    def aggregate_weights(self, clients_params):\n",
    "        clients_params_array = np.concatenate((clients_params))\n",
    "\n",
    "        n_clusters = clients_params[0].shape[0]\n",
    "        model_aggregator = KMeans(n_clusters=n_clusters, init='k-means++')\n",
    "        model_aggregator.fit(clients_params_array)\n",
    "        aggregated_weights = np.array(model_aggregator.cluster_centers_)\n",
    "        return aggregated_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a federated government of clustering, in order to apply this aggregation operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_database = shfl.data_base.Iris()\n",
    "c_train_data, c_train_labels, c_test_data, c_test_labels = c_database.load_data()\n",
    "\n",
    "c_iid_distribution = shfl.data_distribution.IidDataDistribution(c_database)\n",
    "c_federated_data, c_test_data, c_test_labels = c_iid_distribution.get_federated_data(num_nodes=3, percent=50)\n",
    "\n",
    "n_clusters = 3 # Set number of clusters\n",
    "n_features = train_data.shape[1]\n",
    "def clustering_model_builder():\n",
    "    model = shfl.model.KMeansModel(n_clusters=n_clusters, n_features = n_features)\n",
    "    return model\n",
    "\n",
    "clustering_aggregator = ClusterFedAvgAggregator()\n",
    "\n",
    "clustering_federated_government = shfl.federated_government.FederatedGovernment(clustering_model_builder, c_federated_data, clustering_aggregator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_federated_government.run_rounds(1, c_test_data, c_test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
