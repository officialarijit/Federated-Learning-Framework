{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated learning: basic concepts\n",
    "\n",
    "In this notebook we provide a simple example of how to perform an experiment in a federated environment, with the help of Sherpa.ai Federated Learning framework. To set up the federated learning experiment we will show the simple steps for loading the dataset and distribute it to a federated network of clients, and we will define the model that will be trained in the federated learning rounds. \n",
    "## The data\n",
    "We are going to use a popular dataset: the framework provides some functions to load the [Emnist](https://www.nist.gov/itl/products-and-services/emnist-dataset) digits dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import shfl\n",
    "\n",
    "database = shfl.data_base.Emnist()\n",
    "train_data, train_labels, test_data, test_labels = database.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect some properties of the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "print(type(train_data[0]))\n",
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as we have seen, our dataset is composed of a set of matrices that are 28 by 28. Before starting with the federated scenario, we can take a look at a sample of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to simulate a federated learning scenario with a set of client nodes containing private data, and a central server that will be responsible for coordinating the different clients. \n",
    "But, first of all, we have to simulate the data contained in every client. In order to do that, we are going to use the previously loaded dataset . \n",
    "The assumption in this example is that the data is distributed as a set of independent and identically distributed random variables, with every node having approximately the same amount of data. \n",
    "There are a set of different possibilities for distributing the data. \n",
    "The distribution of the data is one of the factors that can have the most impact on a federated algorithm. Therefore, the framework has some of the most common distributions implemented, which allows you to easily experiment with different situations. \n",
    "In [Sampling Methods](./federated_learning_sampling.ipynb), you can dig into the options that the framework provides, at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "iid_distribution = shfl.data_distribution.IidDataDistribution(database)\n",
    "federated_data, test_data, test_labels = iid_distribution.get_federated_data(num_nodes=20, percent=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! We have created federated data from the Emnist dataset using 20 nodes and 10 percent of the available data. \n",
    "This data is a set of data nodes containing private data.  \n",
    "Let's learn a little more about the federated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(type(federated_data))\n",
    "print(federated_data.num_nodes())\n",
    "federated_data[0].private_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, private data in a node is not directly accessible, but the framework provides mechanisms to use this data in a machine learning model. \n",
    "## The model\n",
    "A federated learning algorithm is defined by a machine learning model, locally deployed in each node, that learns from the respective node's private data and an aggregating mechanism to aggregate the different model parameters uploaded by the client nodes to a central node. In this example, we will use a deep learning model using Keras to build it. The framework provides classes on using Tensorflow (see [Tensorflow Model](./federated_learning_basic_concepts_tensorflow.ipynb)) and Keras models in a federated learning scenario, your only job is to create a function acting as model builder. Moreover, the framework provides classes on using pretrained Tensorflow and Keras models (see [Pretrained Model](./federated_learning_basic_concepts_pretrained_model.ipynb)). In this example, we will build a Keras learning model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def model_builder():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', strides=1, input_shape=(28, 28, 1)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(tf.keras.layers.Dropout(0.4))\n",
    "    model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', strides=1))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.1))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    criterion = tf.keras.losses.CategoricalCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.RMSprop()\n",
    "    metrics = [tf.keras.metrics.categorical_accuracy]\n",
    "    \n",
    "    return shfl.model.DeepLearningModel(model=model, criterion=criterion, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the only missing piece is the aggregation operator. Nevertheless, the framework provides some aggregation operators that we can use. In the following piece of code, we define the federated aggregation mechanism. Moreover, we define the federated government based on the Keras learning model, the federated data, and the aggregation mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "aggregator = shfl.federated_aggregator.FedAvgAggregator()\n",
    "federated_government = shfl.federated_government.FederatedGovernment(model_builder, federated_data, aggregator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see all the aggregation operators, you can check out the [Aggregation Operators](./federated_learning_basic_concepts_aggregation_operators.ipynb) notebook. Before running the algorithm, we want to apply a transformation to the data. A good practice is to define a federated operation that will ensure that the transformation is applied to the federated data in all the client nodes. We want to reshape the data, so we define the following FederatedTransformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Reshape(shfl.private.FederatedTransformation):\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = np.reshape(labeled_data.data, (labeled_data.data.shape[0], labeled_data.data.shape[1], labeled_data.data.shape[2],1))\n",
    "        \n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Reshape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we want to normalize the data. We define a federated transformation using mean and standard deviation (std) parameters. We use the mean and std estimated from the training set in this example. Although the ideal parameters would be an aggregation of the mean and std of each client's training datasets, we use the mean and std of the global dataset as a simple approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Normalize(shfl.private.FederatedTransformation):\n",
    "    \n",
    "    def __init__(self, mean, std):\n",
    "        self.__mean = mean\n",
    "        self.__std = std\n",
    "    \n",
    "    def apply(self, labeled_data):\n",
    "        labeled_data.data = (labeled_data.data - self.__mean)/self.__std\n",
    "        \n",
    "        \n",
    "mean = np.mean(train_data.data)\n",
    "std = np.std(train_data.data)\n",
    "shfl.private.federated_operation.apply_federated_transformation(federated_data, Normalize(mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the federated learning experiment\n",
    "We are now ready to execute our federated learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_data = np.reshape(test_data, (test_data.shape[0], test_data.shape[1], test_data.shape[2],1))\n",
    "federated_government.run_rounds(3, test_data, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
